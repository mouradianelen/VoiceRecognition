{
    "metadata": {
        "model": "Net(\n  (conv1): Conv2d(1, 60, kernel_size=(5, 5), stride=(1, 1))\n  (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(60, 160, kernel_size=(5, 5), stride=(1, 1))\n  (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv3): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1))\n  (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc1): Linear(in_features=8000, out_features=120, bias=True)\n  (dropout1): Dropout(p=0.2, inplace=False)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (dropout2): Dropout(p=0.3, inplace=False)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)",
        "freq_bins": 64,
        "time_steps": 64,
        "batch_size": 32,
        "train_set_size": 1560,
        "optimizer": "Adam",
        "loss_function": "CrossEntropyLoss()",
        "num_epochs": 30
    },
    "data": {
        "1": {
            "loss": 0.9727443099021912,
            "lr": 0.001
        },
        "2": {
            "loss": 0.7591640639305115,
            "lr": 0.001
        },
        "3": {
            "loss": 0.639892327785492,
            "lr": 0.001
        },
        "4": {
            "loss": 0.5882551634311676,
            "lr": 0.001
        },
        "5": {
            "loss": 0.5239950430393219,
            "lr": 0.001
        },
        "6": {
            "loss": 0.5316621613502502,
            "lr": 0.001
        },
        "7": {
            "loss": 0.4987941741943359,
            "lr": 0.001
        },
        "8": {
            "loss": 0.4991328179836273,
            "lr": 0.001
        },
        "9": {
            "loss": 0.48375492930412295,
            "lr": 0.001
        },
        "10": {
            "loss": 0.4701369941234589,
            "lr": 0.001
        },
        "11": {
            "loss": 0.46557618498802184,
            "lr": 0.001
        },
        "12": {
            "loss": 0.4405925977230072,
            "lr": 0.001
        },
        "13": {
            "loss": 0.4230485117435455,
            "lr": 0.001
        },
        "14": {
            "loss": 0.43709745883941653,
            "lr": 0.001
        },
        "15": {
            "loss": 0.3991907858848572,
            "lr": 0.001
        },
        "16": {
            "loss": 0.391941591501236,
            "lr": 0.001
        },
        "17": {
            "loss": 0.37616911888122556,
            "lr": 0.001
        },
        "18": {
            "loss": 0.3636966449022293,
            "lr": 0.001
        },
        "19": {
            "loss": 0.36602545261383057,
            "lr": 0.001
        },
        "20": {
            "loss": 0.36047413527965544,
            "lr": 0.001
        },
        "21": {
            "loss": 0.32123896837234495,
            "lr": 0.001
        },
        "22": {
            "loss": 0.3165463173389435,
            "lr": 0.001
        },
        "23": {
            "loss": 0.3396751028299332,
            "lr": 0.001
        },
        "24": {
            "loss": 0.30974668979644776,
            "lr": 0.001
        },
        "25": {
            "loss": 0.31599108040332796,
            "lr": 0.001
        },
        "26": {
            "loss": 0.3563647508621216,
            "lr": 0.001
        },
        "27": {
            "loss": 0.2951899838447571,
            "lr": 0.001
        },
        "28": {
            "loss": 0.3242004019021988,
            "lr": 0.001
        },
        "29": {
            "loss": 0.29328813910484314,
            "lr": 0.001
        },
        "30": {
            "loss": 0.29581384003162386,
            "lr": 0.001
        }
    }
}